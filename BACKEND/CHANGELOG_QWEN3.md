# Changelog - Integra√ß√£o Qwen3-235B-A22B

## üìÖ Data: 04/11/2025

## üéØ Objetivo

Adicionar suporte ao modelo Qwen3-235B-A22B (235B par√¢metros, 22B ativos) via Hugging Face para categoriza√ß√£o de quest√µes m√©dicas com IA.

## ‚ú® Novos Arquivos

### 1. Cliente Qwen3
- **Arquivo:** `src/services/qwenClient.ts`
- **Descri√ß√£o:** Cliente completo para integra√ß√£o com Qwen3-235B-A22B
- **Recursos:**
  - Suporte a modo pensante e n√£o-pensante
  - Contexto extens√≠vel (32k-131k tokens com YaRN)
  - An√°lise de imagens m√©dicas
  - Parsing robusto de respostas JSON
  - Tratamento de erros

### 2. Documenta√ß√£o
- **Arquivo:** `docs/QWEN3_SETUP.md`
- **Descri√ß√£o:** Guia completo de configura√ß√£o e uso do Qwen3
- **Conte√∫do:**
  - Caracter√≠sticas do modelo
  - Instru√ß√µes de configura√ß√£o
  - Modos de opera√ß√£o (pensante vs n√£o-pensante)
  - Explica√ß√£o sobre YaRN
  - Melhores pr√°ticas
  - Compara√ß√£o com outros modelos
  - Troubleshooting

### 3. Guia R√°pido
- **Arquivo:** `QWEN_QUICKSTART.md`
- **Descri√ß√£o:** Guia de in√≠cio r√°pido para usar o Qwen3
- **Conte√∫do:**
  - Configura√ß√£o em 3 passos
  - Configura√ß√µes recomendadas
  - Quando usar Qwen3
  - Troubleshooting r√°pido
  - Compara√ß√£o de performance

### 4. Script de Teste
- **Arquivo:** `scripts/test-qwen.ts`
- **Descri√ß√£o:** Script para testar a integra√ß√£o do Qwen3
- **Testes:**
  - Categoriza√ß√£o simples
  - Categoriza√ß√£o em batch
  - Medi√ß√£o de performance
  - Valida√ß√£o de respostas

## üîß Arquivos Modificados

### 1. Vari√°veis de Ambiente
- **Arquivo:** `.env`
- **Altera√ß√µes:**
  ```bash
  # Novas vari√°veis
  USE_QWEN=false
  QWEN_API_KEY=hf_...
  QWEN_MODEL=Qwen/Qwen3-235B-A22B
  QWEN_BASE_URL=https://api-inference.huggingface.co/models/Qwen/Qwen3-235B-A22B/v1
  QWEN_ENABLE_THINKING=false
  QWEN_MAX_CONTEXT=32768
  ```

### 2. Exemplo de Vari√°veis
- **Arquivo:** `.env.example`
- **Altera√ß√µes:**
  - Adicionadas vari√°veis do Qwen3
  - Reorganizadas vari√°veis de provedores de IA
  - Adicionadas flags USE_* para todos os provedores

### 3. Rotas de Categoriza√ß√£o
- **Arquivo:** `src/routes/categorizationRoutes.ts`
- **Altera√ß√µes:**
  - Importado `createQwenClient`
  - Adicionada l√≥gica de sele√ß√£o do Qwen3
  - Prioridade: Qwen3 > GPT-OSS > MiniMax > Gemini > LM Studio > OpenRouter

### 4. Package.json
- **Arquivo:** `package.json`
- **Altera√ß√µes:**
  - Adicionado script `test:qwen` para testar integra√ß√£o

## üöÄ Como Usar

### Ativar Qwen3

1. Obter API Key do Hugging Face:
   ```
   https://huggingface.co/settings/tokens
   ```

2. Configurar `.env`:
   ```bash
   USE_QWEN=true
   QWEN_API_KEY=hf_seu_token_aqui
   ```

3. Desativar outros provedores:
   ```bash
   USE_GEMINI=false
   USE_GPT_OSS=false
   USE_MINIMAX=false
   ```

4. Testar:
   ```bash
   npm run test:qwen
   ```

### Configura√ß√µes Recomendadas

#### Para Categoriza√ß√£o R√°pida (Padr√£o)
```bash
QWEN_ENABLE_THINKING=false
QWEN_MAX_CONTEXT=32768
```
- Batch size: 5-10 quest√µes
- Tempo: ~3-5s por quest√£o

#### Para An√°lise Profunda
```bash
QWEN_ENABLE_THINKING=true
QWEN_MAX_CONTEXT=32768
```
- Batch size: 1-3 quest√µes
- Tempo: ~10-15s por quest√£o

#### Para Textos Muito Longos
```bash
QWEN_ENABLE_THINKING=false
QWEN_MAX_CONTEXT=131072
```
- Usa YaRN para estender contexto
- Suporta at√© 131k tokens

## üìä Caracter√≠sticas do Qwen3-235B-A22B

### Arquitetura
- **Par√¢metros totais:** 235B
- **Par√¢metros ativos:** 22B (MoE - Mixture of Experts)
- **Contexto nativo:** 32.768 tokens
- **Contexto com YaRN:** 131.072 tokens

### Capacidades
- ‚úÖ Racioc√≠nio complexo (modo pensante)
- ‚úÖ Di√°logo eficiente (modo n√£o-pensante)
- ‚úÖ An√°lise de imagens
- ‚úÖ Suporte multil√≠ngue (100+ idiomas)
- ‚úÖ Gera√ß√£o de JSON estruturado
- ‚úÖ Integra√ß√£o com ferramentas externas

### Par√¢metros de Amostragem

**Modo N√£o-Pensante (Padr√£o):**
- Temperature: 0.7
- Top P: 0.8
- Top K: 20
- Min P: 0

**Modo Pensante:**
- Temperature: 0.6
- Top P: 0.95
- Top K: 20
- Min P: 0

## üîÑ Fluxo de Integra√ß√£o

```
Frontend (Bulk Upload)
    ‚Üì
Backend API (/api/categorization/start)
    ‚Üì
categorizationRoutes.ts
    ‚Üì
initializeServices() ‚Üí Seleciona Qwen3 se USE_QWEN=true
    ‚Üì
createQwenClient(apiKey)
    ‚Üì
batchProcessor.processBatches()
    ‚Üì
categorizationService.categorize()
    ‚Üì
qwenClient.categorize(prompt, batchSize)
    ‚Üì
Hugging Face API (Qwen3-235B-A22B)
    ‚Üì
Resposta JSON parseada
    ‚Üì
Resultados salvos no Supabase
```

## üéØ Prioridade de Provedores

A ordem de prioridade dos provedores de IA √©:

1. **Qwen3** (USE_QWEN=true) - Novo!
2. GPT-OSS (USE_GPT_OSS=true)
3. MiniMax (USE_MINIMAX=true)
4. Gemini (USE_GEMINI=true)
5. LM Studio (USE_LM_STUDIO=true)
6. OpenRouter (padr√£o)

## üìà Compara√ß√£o de Modelos

| Modelo | Par√¢metros | Contexto | Velocidade | Custo | Qualidade |
|--------|-----------|----------|------------|-------|-----------|
| **Qwen3-235B-A22B** | 235B (22B ativos) | 32k-131k | M√©dio | Gratuito* | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| GPT-OSS-120B | 120B | 128k | R√°pido | Gratuito* | ‚≠ê‚≠ê‚≠ê‚≠ê |
| Gemini 2.5 Flash | ? | 1M | Muito R√°pido | Gratuito** | ‚≠ê‚≠ê‚≠ê‚≠ê |
| MiniMax M2 | ? | 200k | R√°pido | Gratuito** | ‚≠ê‚≠ê‚≠ê‚≠ê |

*Via Hugging Face (rate limits aplicam)
**Com limites de quota

## üêõ Troubleshooting

### Erro: "Model is loading"
- **Causa:** Modelo sendo carregado no servidor HF
- **Solu√ß√£o:** Aguardar 1-2 minutos

### Erro: "Rate limit exceeded"
- **Causa:** Limite de requisi√ß√µes gratuitas excedido
- **Solu√ß√£o:** Aguardar ou usar outro provedor

### Resposta truncada
- **Causa:** Resposta muito longa
- **Solu√ß√£o:** Aumentar QWEN_MAX_CONTEXT ou reduzir batch size

### Qualidade baixa
- **Causa:** Modo n√£o-pensante para tarefa complexa
- **Solu√ß√£o:** Ativar QWEN_ENABLE_THINKING=true

## üìö Recursos Adicionais

- [Documenta√ß√£o Oficial Qwen3](https://github.com/QwenLM/Qwen3)
- [Model Card no Hugging Face](https://huggingface.co/Qwen/Qwen3-235B-A22B)
- [Paper YaRN](https://arxiv.org/abs/2309.00071)
- [Hugging Face Inference API](https://huggingface.co/docs/api-inference/index)

## ‚úÖ Checklist de Implementa√ß√£o

- [x] Criar qwenClient.ts
- [x] Atualizar .env com vari√°veis do Qwen3
- [x] Atualizar .env.example
- [x] Integrar em categorizationRoutes.ts
- [x] Criar documenta√ß√£o completa (QWEN3_SETUP.md)
- [x] Criar guia r√°pido (QWEN_QUICKSTART.md)
- [x] Criar script de teste (test-qwen.ts)
- [x] Adicionar script no package.json
- [x] Documentar changelog

## üéâ Pr√≥ximos Passos

1. Testar integra√ß√£o: `npm run test:qwen`
2. Ativar no .env: `USE_QWEN=true`
3. Processar batch de quest√µes
4. Monitorar performance e qualidade
5. Ajustar par√¢metros conforme necess√°rio

## üìù Notas

- O YaRN j√° est√° implementado no modelo, basta ajustar QWEN_MAX_CONTEXT
- Modo n√£o-pensante √© recomendado para categoriza√ß√£o de quest√µes
- Modo pensante √© melhor para an√°lise complexa e racioc√≠nio
- Rate limits do Hugging Face aplicam (considerar HF Pro se necess√°rio)
- Suporte a imagens est√° implementado mas pode ter limita√ß√µes na API gratuita

## ü§ù Contribui√ß√µes

Para melhorias ou problemas:
1. Testar com `npm run test:qwen`
2. Verificar logs do backend
3. Consultar documenta√ß√£o em `docs/QWEN3_SETUP.md`
4. Abrir issue com detalhes do problema
